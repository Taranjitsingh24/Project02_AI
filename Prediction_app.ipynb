{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f98d47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import sklearn\n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44384025",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  same- trained models used to detect the face from the test images\n",
    "face_detector_model = cv2.dnn.readNetFromCaffe('./models/deploy.prototxt.txt',\n",
    "                                               './models/res10_300x300_ssd_iter_140000.caffemodel')\n",
    "# feature extraction\n",
    "face_feature_model = cv2.dnn.readNetFromTorch('./models/openface.nn4.small2.v1.t7')\n",
    "# emotion recognition model\n",
    "emotion_recognition_model = pickle.load(open('./models/emotion_detection.pkl',mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c507420f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy\n",
      "30.79%\n",
      "angry\n",
      "25.21%\n",
      "neutral\n",
      "34.62%\n"
     ]
    }
   ],
   "source": [
    "#  image to test the results from the test folder\n",
    "img = cv2.imread('./test/test1.jpg')\n",
    "image = img.copy()\n",
    "h,w = img.shape[:2]\n",
    "# face detection\n",
    "img_blob = cv2.dnn.blobFromImage(img,1,(300,300),(104,177,123),swapRB=False,crop=False)\n",
    "face_detector_model.setInput(img_blob)\n",
    "detections = face_detector_model.forward()\n",
    "if len(detections) > 0:\n",
    "    for i, confidence in enumerate(detections[0, 0, :, 2]):\n",
    "        if confidence > 0.5:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            startx, starty, endx, endy = box.astype(int)\n",
    "            cv2.rectangle(img,(startx, starty), (endx, endy), (0, 255, 0))\n",
    "\n",
    "\n",
    "            # feature extraction\n",
    "            face_roi = img[starty:endy, startx:endx]\n",
    "            face_blob = cv2.dnn.blobFromImage(face_roi, 1 / 255, (96, 96), (0, 0, 0), swapRB=True, crop=True)\n",
    "            face_feature_model.setInput(face_blob)\n",
    "            vectors = face_feature_model.forward()\n",
    "            # EMOTION\n",
    "            emotion_name = emotion_recognition_model.predict(vectors)[0]\n",
    "            emotion_score = emotion_recognition_model.predict_proba(vectors).max()*100\n",
    "            emotion_score_percent = \"{:.2f}\".format(emotion_score)\n",
    "#             printing the name of the emotion with score\n",
    "            print(emotion_name)\n",
    "            print(emotion_score_percent +\"%\")\n",
    "#             display the box around on the detected face on the image with results\n",
    "            text_emotion = '{} : {:.0f} %'.format(emotion_name, 100 * emotion_score)\n",
    "            cv2.putText(img, text_emotion, (startx, endy), cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 255), 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow('Emotion_Detection',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f08811",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "## this project sucessfully detected the face from the images and also successfuly detected the emotions around the faces.\n",
    "## the accuracy was very low for the project, but this accuracy was expected because of the small dataset. more accuracy can be achieved by adding more images with emotions in the dataset. which required more space and power in the machine. this project was still accurately achieved the results from the test image image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2900b388",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
